{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiaozihan/compiler/blob/main/take_home_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Fun project\n",
        "\n",
        "# Unusual allowances:\n",
        "\n",
        "- You should copy these files to your computer and edit in your own environment\n",
        "  so that you can use the trace functionality. If the CodeSignal platform said\n",
        "  anything about not doing this, ignore it. We'll ignore any warnings the\n",
        "  platform gives due to this allowance.\n",
        "- You're welcome to use any online resources including language models. In fact\n",
        "  you're encouraged to install Github Copilot, it'll likely only help a little.\n",
        "  CodeSignal makes you promise that you'll only use language reference\n",
        "  resources, there's no way to disable that promise, you're welcome to use\n",
        "  non-language resources.\n",
        "- You may use any libraries you want while debugging but your uploaded solution\n",
        "  must use only the standard library.\n",
        "\n",
        "# Rules\n",
        "\n",
        "- You may not consult with anyone else while you're doing this problem.\n",
        "- Please don't tell anyone else about the details of this problem other than the\n",
        "  vague description communicated before you started.\n",
        "\n",
        "# Task\n",
        "\n",
        "- Optimize the kernel (in KernelBuilder.build_kernel) as much as possible in the\n",
        "  available time.\n",
        "    - The machine parameters are balanced so that how impressed we are by you\n",
        "      doing an optimization is roughly proportional to its speedup factor.\n",
        "      Although it's not perfect.\n",
        "    - The exception to the above is doing basic multicore, which we recommend\n",
        "      you start with as a warmup.\n",
        "    - The input used in test_kernel_cycles is what your performance will be\n",
        "      scored on.\n",
        "\n",
        "# Tips\n",
        "\n",
        "- You'll be evaluated primarily on the speed of your correct kernel submissions.\n",
        "  You're encouraged to improve the debugging/trace tooling present in this file,\n",
        "  but only implement tooling and write nice code to the extent that in your\n",
        "  judgement it'll best help you achieve a fast and correct solution.\n",
        "- Try to keep a copy of your first correct kernel somewhere so you can compare\n",
        "  against it when debugging.\n",
        "- Modifying the simulator is one of the most powerful debugging tools available,\n",
        "  you should take advantage of it. But your solution will be tested with an\n",
        "  unmodified simulator so don't change the behavior or API.\n",
        "\n",
        "We recommend you read through problem.py next.\n",
        "\"\"\"\n",
        "\n",
        "import random\n",
        "import unittest\n",
        "\n",
        "from problem import *\n",
        "\n",
        "\n",
        "class KernelBuilder:\n",
        "    def __init__(self):\n",
        "        self.instrs = []\n",
        "        self.labels = {}\n",
        "        self.scratch = {}\n",
        "        self.scratch_debug = {}\n",
        "        self.scratch_ptr = 0\n",
        "        self.const_map = {}\n",
        "\n",
        "    def debug_info(self):\n",
        "        # Hint: This isn't consumed anywhere, but you should probably use it in some way for debugging\n",
        "        return DebugInfo(scratch_map=self.scratch_debug)\n",
        "\n",
        "    def build(self, slots: list[tuple[Engine, tuple]], vliw: bool = False):\n",
        "        # Simple slot packing that just uses one slot per instruction bundle\n",
        "        # print(\"slots: \", slots)\n",
        "        instrs = []\n",
        "        for engine, slot in slots:\n",
        "            instrs.append({engine: [slot]})\n",
        "        return instrs\n",
        "\n",
        "    def add(self, engine, slot):\n",
        "        self.instrs.append({engine: [slot]})\n",
        "\n",
        "    def label(self, name):\n",
        "        self.labels[name] = len(self.instrs)\n",
        "\n",
        "    def alloc_scratch(self, name=None, length=1):\n",
        "        addr = self.scratch_ptr\n",
        "        if name is not None:\n",
        "            self.scratch[name] = addr\n",
        "            self.scratch_debug[addr] = (name, length)\n",
        "        self.scratch_ptr += length\n",
        "        assert self.scratch_ptr <= SCRATCH_SIZE, \"Out of scratch space\"\n",
        "        return addr\n",
        "\n",
        "    def scratch_const(self, val, name=None):\n",
        "        if val not in self.const_map:\n",
        "            addr = self.alloc_scratch(name)\n",
        "            self.add(\"load\", (\"const\", addr, val))\n",
        "            self.const_map[val] = addr\n",
        "        return self.const_map[val]\n",
        "\n",
        "    def for_loop(self, iter_addr, limit_addr, body: list[Instruction]):\n",
        "        \"\"\"\n",
        "        A for loop that runs len times\n",
        "        \"\"\"\n",
        "        loop_cond = self.alloc_scratch()\n",
        "        one_constant = self.scratch_const(1)\n",
        "        start_addr = len(self.instrs)\n",
        "        prologue_len, epilogue_len = 3, 1\n",
        "        end_addr = start_addr + prologue_len + len(body) + epilogue_len\n",
        "        instrs = [\n",
        "            {\"alu\": [(\"+\", iter_addr, one_constant, iter_addr)]},\n",
        "            {\"alu\": [(\"<\", loop_cond, limit_addr, iter_addr)]},\n",
        "            {\"flow\": [(\"cond_jump\", loop_cond, end_addr)]},\n",
        "        ]\n",
        "        instrs.extend(body)\n",
        "        instrs.append({\"flow\": [(\"jump\", start_addr)]})\n",
        "        return instrs\n",
        "\n",
        "    def build_simple_test(self):\n",
        "        \"\"\"\n",
        "        A simple test program that just counts to 10\n",
        "        \"\"\"\n",
        "        # Scratch space addresses\n",
        "        one_constant = self.scratch_const(1)\n",
        "        accum = self.alloc_scratch(\"accum\")\n",
        "        iter_addr = self.alloc_scratch(\"iter\")\n",
        "        limit_addr = self.alloc_scratch(\"limit\")\n",
        "        self.add(\"load\", (\"const\", limit_addr, 10))\n",
        "        body = [(\"alu\", (\"+\", accum, accum, one_constant))]\n",
        "        self.instrs.extend(self.for_loop(iter_addr, limit_addr, self.build(body)))\n",
        "\n",
        "    def build_hash_vectorized(self, v_val_hash_addr, v_tmp1, v_tmp2):\n",
        "        \"\"\"\n",
        "        Vectorized version of the hash function.\n",
        "\n",
        "        Args:\n",
        "            v_val_hash_addr: Scratch address of the *input vector* (and final output).\n",
        "            v_tmp1:          Scratch address of a temporary vector.\n",
        "            v_tmp2:          Scratch address of another temporary vector.\n",
        "        \"\"\"\n",
        "        slots = []\n",
        "        v_const = self.alloc_scratch(\"v_const\", VLEN) # Allocate a temporary vector for constants\n",
        "\n",
        "        for op1, val1, op2, op3, val3 in HASH_STAGES:\n",
        "            # Broadcast the constant val1 to the v_const vector\n",
        "            slots.append((\"load\", (\"const\", v_tmp1, val1)))\n",
        "            slots.append((\"valu\", (\"vbroadcast\", v_const, v_tmp1)))\n",
        "\n",
        "            if op1 == '+':\n",
        "                slots.append((\"valu\", (\"+\", v_tmp1, v_val_hash_addr, v_const)))\n",
        "            elif op1 == '^':\n",
        "                slots.append((\"valu\", (\"^\", v_tmp1, v_val_hash_addr, v_const)))\n",
        "\n",
        "            # Broadcast val3\n",
        "            slots.append((\"load\", (\"const\", v_tmp2, val3))) # Load immediate\n",
        "            slots.append((\"valu\", (\"vbroadcast\", v_const, v_tmp2))) # vbroadcast\n",
        "\n",
        "            if op3 == \"<<\":\n",
        "                slots.append((\"valu\", (\"<<\", v_tmp2, v_val_hash_addr, v_const)))\n",
        "            elif op3 == \">>\":\n",
        "                slots.append((\"valu\", (\">>\", v_tmp2, v_val_hash_addr, v_const)))\n",
        "            if op2 == '+':\n",
        "                slots.append((\"valu\", (\"+\", v_val_hash_addr, v_tmp1, v_tmp2)))\n",
        "            elif op2 == '^':\n",
        "                slots.append((\"valu\", (\"^\", v_val_hash_addr, v_tmp1, v_tmp2)))\n",
        "\n",
        "        return slots\n",
        "\n",
        "    def build_hash(self, val_hash_addr, tmp1, tmp2):\n",
        "        slots = []\n",
        "\n",
        "        for op1, val1, op2, op3, val3 in HASH_STAGES:\n",
        "            slots.append((\"alu\", (op1, tmp1, val_hash_addr, self.scratch_const(val1))))\n",
        "            slots.append((\"alu\", (op3, tmp2, val_hash_addr, self.scratch_const(val3))))\n",
        "            slots.append((\"alu\", (op2, val_hash_addr, tmp1, tmp2)))\n",
        "\n",
        "        return slots\n",
        "\n",
        "    def build_kernel(self, forest_height: int, n_nodes: int, batch_size: int):\n",
        "        \"\"\"\n",
        "        Like reference_kernel2 but building actual instructions, vectorized.\n",
        "        Just the simplest implementation and non-overlapping scheduling possible.\n",
        "\n",
        "        batch_size is guaranteed to be a multiple of VLEN*N_CORES*16\n",
        "        \"\"\"\n",
        "        tmp1 = self.alloc_scratch(\"tmp1\")\n",
        "        tmp2 = self.alloc_scratch(\"tmp2\")\n",
        "        # Scratch space addresses\n",
        "        init_vars = [\n",
        "            \"rounds\",\n",
        "            \"n_nodes\",\n",
        "            \"batch_size\",\n",
        "            \"forest_height\",\n",
        "            \"forest_values_p\",\n",
        "            \"inp_indices_p\",\n",
        "            \"inp_values_p\",\n",
        "        ]\n",
        "        for v in init_vars:\n",
        "            self.alloc_scratch(v, 1)\n",
        "        for i, v in enumerate(init_vars):\n",
        "            # initialize a space in mem\n",
        "            self.add(\"load\", (\"const\", tmp1, i))\n",
        "            # move to scratch space\n",
        "            self.add(\"load\", (\"load\", self.scratch[v], tmp1))\n",
        "\n",
        "        # create consts in mem so it comes handy later\n",
        "        zero_const = self.scratch_const(0)\n",
        "        one_const = self.scratch_const(1)\n",
        "        two_const = self.scratch_const(2)\n",
        "\n",
        "        # Create a vector of twos for the modulo operation and conditional set operations\n",
        "        # Why can't this be avoided? I hoped there would be a better instruction for this so we can save space?\n",
        "        # Not sure if it works in the same way in real GPUs.\n",
        "        v_zero = self.alloc_scratch(\"v_zero\", VLEN)\n",
        "        v_ones = self.alloc_scratch(\"v_ones\", VLEN)\n",
        "        v_twos = self.alloc_scratch(\"v_twos\", VLEN)\n",
        "\n",
        "        self.add(\"valu\", (\"vbroadcast\", v_zero, zero_const))\n",
        "        self.add(\"valu\", (\"vbroadcast\", v_ones, one_const))\n",
        "        self.add(\"valu\", (\"vbroadcast\", v_twos, two_const))\n",
        "\n",
        "\n",
        "        vector_length_const = self.scratch_const(VLEN)\n",
        "        n_cores_const = self.scratch_const(N_CORES)\n",
        "\n",
        "        # Get core ID\n",
        "        self.add(\"flow\", (\"coreid\", tmp1))\n",
        "\n",
        "        # Calculate items per core\n",
        "        items_per_core = self.alloc_scratch(\"items_per_core\")\n",
        "        self.add(\"alu\", (\"//\", items_per_core, self.scratch[\"batch_size\"], n_cores_const))\n",
        "\n",
        "        # Calculate vectors per core\n",
        "        vectors_per_core = self.alloc_scratch(\"vectors_per_core\")\n",
        "        self.add(\"alu\", (\"//\", vectors_per_core, items_per_core, vector_length_const))\n",
        "\n",
        "        # Calculate core offset (in items)\n",
        "        core_offset = self.alloc_scratch(\"core_offset\")\n",
        "        self.add(\"alu\", (\"*\", core_offset, tmp1, items_per_core))\n",
        "\n",
        "        # Pause\n",
        "        self.add(\"flow\", (\"pause\",))\n",
        "        self.add(\"debug\", (\"comment\", \"Starting loop after init\"))\n",
        "\n",
        "        # inint things\n",
        "        body = []\n",
        "        v_idx = self.alloc_scratch(\"v_idx\", VLEN)  # Vector of indices\n",
        "        v_val = self.alloc_scratch(\"v_val\", VLEN)  # Vector of values\n",
        "        v_node_val = self.alloc_scratch(\"v_node_val\", VLEN) # Vector of node values\n",
        "        v_tmp = self.alloc_scratch(\"v_tmp\", VLEN) # Temporary vector\n",
        "        v_tmp2 = self.alloc_scratch(\"v_tmp2\", VLEN) # Temporary vector\n",
        "        v_offset = self.alloc_scratch(\"v_offset\", VLEN) # Vector of offsets within a core's chunk\n",
        "\n",
        "        # print(\"body:\", body)\n",
        "\n",
        "        # Create a vector of offsets\n",
        "        for i in range(VLEN):\n",
        "            body.append((\"load\", (\"const\", v_offset + i, i)))\n",
        "\n",
        "        # Assuming batch_size is a multiple of N_CORES*VLEN*16, my code can't handle the remainder\n",
        "\n",
        "        for i in range(batch_size // (N_CORES * VLEN)):\n",
        "            # Calculate the base address for this vector within the core's chunk\n",
        "            body.append((\"alu\", (\"*\", tmp1, self.scratch_const(i * VLEN), one_const))) # i*VLEN\n",
        "            body.append((\"alu\", (\"+\", tmp1, core_offset, tmp1))) # core_offset + i*VLEN\n",
        "\n",
        "            # Load a vector of indices:  inp_indices[core_offset + i*VLEN : core_offset + i*VLEN + VLEN]\n",
        "            body.append((\"alu\", (\"+\", tmp2, self.scratch[\"inp_indices_p\"], tmp1))) # Calculate address\n",
        "            body.append((\"load\", (\"vload\", v_idx, tmp2))) # Vector load\n",
        "\n",
        "\n",
        "            # Load corresponding node values: forest_values[v_idx[0]], forest_values[v_idx[1]], ...\n",
        "            for idx_in_vector in range(VLEN):\n",
        "                body.append((\"alu\", (\"+\", v_tmp+idx_in_vector, self.scratch[\"forest_values_p\"], v_idx+idx_in_vector))) # v_tmp now has addresses\n",
        "            for idx_in_vector in range(VLEN):\n",
        "                body.append((\"load\", (\"load\", v_node_val+idx_in_vector, v_tmp+idx_in_vector)))\n",
        "            # Load a vector of values:  inp_values[core_offset + i*VLEN : core_offset + i*VLEN + VLEN]\n",
        "            body.append((\"alu\", (\"+\", tmp2, self.scratch[\"inp_values_p\"], tmp1)))  # Calculate address\n",
        "            body.append((\"load\", (\"vload\", v_val, tmp2)))  # Vector load\n",
        "\n",
        "            # Vectorized XOR: v_val = v_val ^ v_node_val\n",
        "            for idx_in_vector in range(VLEN):\n",
        "                body.append((\"alu\", (\"^\", v_val+idx_in_vector, v_val+idx_in_vector, v_node_val+idx_in_vector)))\n",
        "            for idx_in_vector in range(VLEN):\n",
        "                body.extend(self.build_hash(v_val+idx_in_vector, v_tmp, v_tmp2))\n",
        "\n",
        "            # Vectorized hash.\n",
        "            #body.extend(self.build_hash_vectorized(v_val, v_tmp, tmp2))\n",
        "            # body.extend(self.build_hash(v_val, v_tmp, tmp2))\n",
        "            # body.extend(self.build_hash(v_val+1, v_tmp+1, tmp2+1))\n",
        "            body.append((\"debug\", (\"comment\", \"after hashing\")))\n",
        "            # Vectorized calculation of next index\n",
        "            body.append((\"valu\", (\"%\", v_tmp, v_val, v_twos)))  # v_tmp = v_val % 2\n",
        "            body.append((\"valu\", (\"==\", v_tmp, v_tmp, v_zero)))      # v_tmp = (v_tmp == 0) ? 1 : 0\n",
        "            body.append((\"flow\", (\"vselect\", v_tmp, v_tmp, v_ones, v_twos))) # v_tmp = (val % 2 == 0) ? 1 : 2\n",
        "            body.append((\"debug\", (\"comment\", \"debbbbbuggg\")))\n",
        "            body.append((\"valu\", (\"*\", v_idx, v_idx, v_twos)))  # v_idx = 2 * v_idx\n",
        "            body.append((\"valu\", (\"+\", v_idx, v_idx, v_tmp)))    # v_idx = v_idx + v_tmp\n",
        "\n",
        "            body.append((\"debug\", (\"comment\", \"comparing to n_nodes\")))\n",
        "            # Vectorized wraparound\n",
        "            for idx_in_vector in range(VLEN):\n",
        "                body.append((\"alu\", (\"<\", v_tmp + idx_in_vector, v_idx + idx_in_vector, self.scratch[\"n_nodes\"]))) #v_tmp = (v_idx<n_nodes)\n",
        "            body.append((\"flow\", (\"vselect\", v_idx, v_tmp, v_idx, v_zero))) # v_idx = v_tmp?v_idx:zero_const\n",
        "\n",
        "            # Store updated vector of indices\n",
        "            body.append((\"alu\", (\"+\", tmp2, self.scratch[\"inp_indices_p\"], tmp1)))\n",
        "            body.append((\"store\", (\"vstore\", tmp2, v_idx)))\n",
        "\n",
        "            # Store updated vector of values\n",
        "            body.append((\"alu\", (\"+\", tmp2, self.scratch[\"inp_values_p\"], tmp1)))\n",
        "            body.append((\"store\", (\"vstore\", tmp2, v_val)))  # Store the hashed values\n",
        "\n",
        "        body_instrs = self.build(body)\n",
        "        body_instrs.append({\"flow\": [(\"pause\",)]})\n",
        "        height_i = self.alloc_scratch(\"height_i\")\n",
        "        loop = self.for_loop(height_i, self.scratch[\"rounds\"], body_instrs)\n",
        "        self.instrs.extend(loop)\n",
        "\n",
        "\n",
        "def do_kernel_test(\n",
        "    forest_height: int,\n",
        "    rounds: int,\n",
        "    batch_size: int,\n",
        "    seed: int = 123,\n",
        "    trace: bool = False,\n",
        "    prints: bool = True,\n",
        "):\n",
        "    print(f\"{forest_height=}, {rounds=}, {batch_size=}\")\n",
        "    random.seed(seed)\n",
        "    forest = Tree.generate(forest_height)\n",
        "    inp = Input.generate(forest, batch_size, rounds)\n",
        "    mem = build_mem_image(forest, inp)\n",
        "\n",
        "    print(\"mem:\", mem)\n",
        "\n",
        "    kb = KernelBuilder()\n",
        "    kb.build_kernel(forest.height, len(forest.values), len(inp.indices))\n",
        "    # print(kb.instrs)\n",
        "\n",
        "    machine = Machine(mem, kb.instrs, kb.debug_info(), n_cores=N_CORES, trace=trace)\n",
        "    machine.prints = prints\n",
        "\n",
        "    for i, ref_mem in enumerate(reference_kernel2(mem)):\n",
        "        machine.run()\n",
        "        inp_values_p = ref_mem[6]\n",
        "        print(\"input values position: \", inp_values_p)\n",
        "        if True:\n",
        "            print(\"hello:\", machine.mem[inp_values_p : inp_values_p + len(inp.values)])\n",
        "            print(\"hi:\", ref_mem[inp_values_p : inp_values_p + len(inp.values)])\n",
        "        print(\"new mem:\", machine.mem)\n",
        "        assert (\n",
        "            machine.mem[inp_values_p : inp_values_p + len(inp.values)]\n",
        "            == ref_mem[inp_values_p : inp_values_p + len(inp.values)]\n",
        "        ), f\"Incorrect result on round {i}\"\n",
        "        inp_indices_p = ref_mem[5]\n",
        "        if True:\n",
        "            print(\"hey:\", machine.mem[inp_indices_p : inp_indices_p + len(inp.indices)])\n",
        "            print(\"there:\", ref_mem[inp_indices_p : inp_indices_p + len(inp.indices)])\n",
        "        # Updating these in memory isn't required, but you can enable this check for debugging\n",
        "        #assert machine.mem[inp_indices_p:inp_indices_p+len(inp.indices)] == ref_mem[inp_indices_p:inp_indices_p+len(inp.indices)]\n",
        "\n",
        "    print(\"CYCLES: \", machine.cycle)\n",
        "    return machine.cycle\n",
        "\n",
        "\n",
        "class Tests(unittest.TestCase):\n",
        "    def test_ref_kernels(self):\n",
        "        \"\"\"\n",
        "        Test the reference kernels against each other\n",
        "        \"\"\"\n",
        "        random.seed(123)\n",
        "        for i in range(10):\n",
        "            f = Tree.generate(4)\n",
        "            inp = Input.generate(f, 10, 6)\n",
        "            mem = build_mem_image(f, inp)\n",
        "            reference_kernel(f, inp)\n",
        "            for _ in reference_kernel2(mem):\n",
        "                pass\n",
        "            assert inp.indices == mem[mem[5] : mem[5] + len(inp.indices)]\n",
        "            assert inp.values == mem[mem[6] : mem[6] + len(inp.values)]\n",
        "\n",
        "    def test_simple(self):\n",
        "        # Test the kernel builder\n",
        "        kb = KernelBuilder()\n",
        "        kb.build_simple_test()\n",
        "        # print(kb.instrs)\n",
        "\n",
        "        # Test the machine\n",
        "        mem = [0] * 10\n",
        "        machine = Machine(mem, kb.instrs, kb.debug_info())\n",
        "        machine.prints = True\n",
        "        machine.run()\n",
        "        # print(machine.cores[0])\n",
        "        assert machine.cores[0].scratch[1] == 10\n",
        "\n",
        "    def test_kernel_trace(self):\n",
        "        # Tiny example for correctness debugging\n",
        "        # do_kernel_test(3, 1, 1, trace=True, prints=True)\n",
        "        # Full-scale example for performance testing\n",
        "        do_kernel_test(3, 3, 16, trace=True, prints=False)\n",
        "\n",
        "    def test_kernel_correctness(self):\n",
        "        # Technically passing this test is not required for submission, see submission_tests.py for the actual correctness test\n",
        "        # Feel free not to run this yourself if your compiler is slow at it\n",
        "        for batch in range(1, 3):\n",
        "            for forest_height in range(3):\n",
        "                do_kernel_test(\n",
        "                    forest_height + 2, forest_height + 4, batch * 16 * VLEN * N_CORES\n",
        "                )\n",
        "\n",
        "    def test_kernel_cycles(self):\n",
        "        do_kernel_test(10, 16, 1024)\n",
        "\n",
        "\n",
        "# To run all the tests:\n",
        "#    python perf_takehome.py\n",
        "# To run a specific test:\n",
        "#    python perf_takehome.py Tests.test_kernel_cycles\n",
        "# To view a hot-reloading trace of all the instructions:  **Recommended debug loop**\n",
        "#    python perf_takehome.py Tests.test_kernel_trace\n",
        "# Then run `python watch_trace.py` in another tab, it'll open a browser tab, then click \"Open Perfetto\"\n",
        "# You can then keep that open and re-run the test to see a new trace.\n",
        "\n",
        "# To test the actual submission tests that CodeSignal will run:\n",
        "#    python tests/submission_tests.py\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main()\n"
      ],
      "metadata": {
        "id": "Bfx3N47r-tzE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}